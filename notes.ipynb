{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pa3oOp8gYv8D"
      },
      "id": "pa3oOp8gYv8D",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Basic operations**"
      ],
      "metadata": {
        "id": "38AO11J2oiIm"
      },
      "id": "38AO11J2oiIm"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "gmM5lKAzYwxJ",
        "outputId": "200e1ed7-9f89-4016-cb83-2a41f14b4286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gmM5lKAzYwxJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "print(x.size())"
      ],
      "metadata": {
        "id": "WEVfmp1tY9y-",
        "outputId": "8fb06826-1990-4946-f64b-4cd933fbc918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WEVfmp1tY9y-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1260, 0.8862, 0.8999]], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1,2,3])\n",
        "x"
      ],
      "metadata": {
        "id": "lp9MhngKZYS6",
        "outputId": "58234fb1-e6ef-4db0-a7ad-c9271cefbee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lp9MhngKZYS6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inplace\n",
        "x = torch.rand(1,3)\n",
        "x.mul_(0)\n",
        "x"
      ],
      "metadata": {
        "id": "EgRZoOrUZdsD",
        "outputId": "05f75d23-c650-4d1c-ae33-28a691e378e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EgRZoOrUZdsD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2)\n",
        "x.view(4)"
      ],
      "metadata": {
        "id": "DhmGgJmxZzLm",
        "outputId": "88c4dc1d-cdf6-49f6-bc45-8185eb89dead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DhmGgJmxZzLm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3538, 0.9742, 0.0030, 0.6858])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# takes reference if it's on gpu\n",
        "x.numpy()"
      ],
      "metadata": {
        "id": "MbJHW9acaYw0",
        "outputId": "b917ea7b-3b56-4072-a15c-ebfde1a63330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MbJHW9acaYw0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35384423, 0.97419006],\n",
              "       [0.00295287, 0.6857872 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# takes reference if it's on gpu\n",
        "x = np.array([1,2,3])\n",
        "torch.from_numpy(x)"
      ],
      "metadata": {
        "id": "HPayYoFSbKnx",
        "outputId": "22d61325-93ac-4cc1-97f9-e259f07b8487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HPayYoFSbKnx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cpu\")\n",
        "  x = torch.ones(5, device=device)\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device)\n",
        "  z = x+y\n",
        "  z = z.to(\"cpu\")\n",
        "  print(z)"
      ],
      "metadata": {
        "id": "Grs3MjEHbTnQ",
        "outputId": "f41d482f-62fe-4ed9-e21f-805855ceb65a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Grs3MjEHbTnQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient for scalars\n",
        "x = torch.ones(3, requires_grad=True)\n",
        "y = x + 2\n",
        "z = y*y*2\n",
        "z = z.mean()\n",
        "print(y)\n",
        "print(z)\n",
        "z.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPD-pVWnHJXr",
        "outputId": "1d70e30c-a44e-405c-a1ee-01cef9638c13"
      },
      "id": "qPD-pVWnHJXr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3.], grad_fn=<AddBackward0>)\n",
            "tensor(18., grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 4., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient for scalars\n",
        "x = torch.ones(3, requires_grad=True)\n",
        "y = x + 2\n",
        "z = y*y*2\n",
        "# z = z.mean()\n",
        "print(y)\n",
        "print(z)\n",
        "z.backward(gradient=torch.tensor([1,1,1]))\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zIybqrKH2cj",
        "outputId": "3168b02a-6a4a-497f-c781-2c84311035b1"
      },
      "id": "6zIybqrKH2cj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3.], grad_fn=<AddBackward0>)\n",
            "tensor([18., 18., 18.], grad_fn=<MulBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12., 12., 12.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# desible requires grad. 3 way\n",
        "# .requires_grad_(False)\n",
        "# .detach()\n",
        "# with torch.no_grad():\n",
        "\n",
        "x1 = torch.randn(3, requires_grad=True)\n",
        "x2 = torch.randn(3, requires_grad=True)\n",
        "x3 = torch.randn(3, requires_grad=True)\n",
        "x1.requires_grad_(False)\n",
        "print(x1)\n",
        "x2.detach_()\n",
        "print(x2)\n",
        "with torch.no_grad():\n",
        "  y = x3 * 2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV6yJF83NAKq",
        "outputId": "035396e2-5b84-445c-f384-73636c3ddda9"
      },
      "id": "oV6yJF83NAKq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.6437, 1.5856, 0.6697])\n",
            "tensor([0.9452, 1.2962, 0.8772])\n",
            "tensor([ 2.8175, -1.6636, -0.8369])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# warning pytorch accumulates gradients\n",
        "# model simulation\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "\n",
        "print(\"we need to clear the gradients\")\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEJCC3QrOQs-",
        "outputId": "eef1684f-ce2e-4376-fda9-707df3954514"
      },
      "id": "wEJCC3QrOQs-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n",
            "we need to clear the gradients\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # model simulation\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "y_hat = w*x\n",
        "loss = (y_hat-y)**2\n",
        "print(loss)\n",
        "loss.backward()\n",
        "w.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xZ8TrgrPJMS",
        "outputId": "511a9f44-0371-48e0-ba5f-667d23618e68"
      },
      "id": "1xZ8TrgrPJMS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Linear Regression**"
      ],
      "metadata": {
        "id": "uDrdCka0oQaI"
      },
      "id": "uDrdCka0oQaI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "\n",
        "# 0) Prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32)).view(-1, 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "    \n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "zNkG7Uld31Uq",
        "outputId": "ada60219-98d8-4fcb-f1ff-302d62a50ac2"
      },
      "id": "zNkG7Uld31Uq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 4134.0151\n",
            "epoch: 20, loss = 2910.5952\n",
            "epoch: 30, loss = 2076.9443\n",
            "epoch: 40, loss = 1508.7603\n",
            "epoch: 50, loss = 1121.4236\n",
            "epoch: 60, loss = 857.3167\n",
            "epoch: 70, loss = 677.1964\n",
            "epoch: 80, loss = 554.3298\n",
            "epoch: 90, loss = 470.5013\n",
            "epoch: 100, loss = 413.2964\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Logistic Regression**"
      ],
      "metadata": {
        "id": "X9qVwVvRoIJy"
      },
      "id": "X9qVwVvRoIJy"
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(-1, 1)\n",
        "y_test = y_test.view(-1, 1)\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqSJbBsVnukw",
        "outputId": "abd4da8c-d400-4eb8-ef9b-3a539f02440d"
      },
      "id": "LqSJbBsVnukw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.5837\n",
            "epoch: 20, loss = 0.4820\n",
            "epoch: 30, loss = 0.4177\n",
            "epoch: 40, loss = 0.3732\n",
            "epoch: 50, loss = 0.3403\n",
            "epoch: 60, loss = 0.3148\n",
            "epoch: 70, loss = 0.2942\n",
            "epoch: 80, loss = 0.2772\n",
            "epoch: 90, loss = 0.2628\n",
            "epoch: 100, loss = 0.2504\n",
            "accuracy: 0.8947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data**"
      ],
      "metadata": {
        "id": "Mfp2-7198_CH"
      },
      "id": "Mfp2-7198_CH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Custom**"
      ],
      "metadata": {
        "id": "AfAohmnm-Y35"
      },
      "id": "AfAohmnm-Y35"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset**"
      ],
      "metadata": {
        "id": "hgE5dNJC9DT3"
      },
      "id": "hgE5dNJC9DT3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a custom Dataset:\n",
        "# inherit Dataset\n",
        "# implement __init__ , __getitem__ , and __len__\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  \n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('/content/drive/MyDrive/data/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # note that we do not convert to tensor here\n",
        "        self.x_data = xy[:, 1:]\n",
        "        self.y_data = xy[:, [0]]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# create dataset\n",
        "dataset = WineDataset()"
      ],
      "metadata": {
        "id": "9k_vnTKN90lE"
      },
      "id": "9k_vnTKN90lE",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data loader**"
      ],
      "metadata": {
        "id": "42sKlnef-PJe"
      },
      "id": "42sKlnef-PJe"
    },
    {
      "cell_type": "code",
      "source": [
        "# get first sample and unpack\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)"
      ],
      "metadata": {
        "id": "PNv9HvUw_RH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28ebb7c-0575-463b-acd6-8e3a7b9af22e"
      },
      "id": "PNv9HvUw_RH6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data transformer**"
      ],
      "metadata": {
        "id": "RpqYRIVT9JWS"
      },
      "id": "RpqYRIVT9JWS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Transforms\n",
        "# implement __call__(self, sample)\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "    # multiply inputs with a given factor\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets"
      ],
      "metadata": {
        "id": "OZX34r-A_dHO"
      },
      "id": "OZX34r-A_dHO",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Without Transform')\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor Transform')\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor and Multiplication Transform')\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)"
      ],
      "metadata": {
        "id": "FIh1iGc-_nSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b62e0db-86b9-4ef0-f047-fb292dfe56ff"
      },
      "id": "FIh1iGc-_nSW",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Transform\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n",
            "\n",
            "With Tensor Transform\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n",
            "\n",
            "With Tensor and Multiplication Transform\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
            "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
            "        4.2600e+03]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pytorch**"
      ],
      "metadata": {
        "id": "_158A5Ac9Jdh"
      },
      "id": "_158A5Ac9Jdh"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=3,\n",
        "                          shuffle=True)\n",
        "\n",
        "\n",
        "# look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = dataiter.next()\n",
        "inputs, targets = data\n",
        "print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "id": "L9MtLtvL9Gz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cbdcf7-3188-4eee-c626-7fc3f125a1ec"
      },
      "id": "L9MtLtvL9Gz8",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 28, 28]) torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Softmax - Cross Entropy**"
      ],
      "metadata": {
        "id": "LOulOV-oHmWe"
      },
      "id": "LOulOV-oHmWe"
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic data\n",
        "y_true = torch.tensor([1, 0, 0])\n",
        "\n",
        "y_pred1 = torch.tensor([8, 4, 4], dtype=torch.float32)\n",
        "y_pred2 = torch.tensor([-5, 7, 9], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "9sOpvDuDHqDt"
      },
      "id": "9sOpvDuDHqDt",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_softmax(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "print('my softmax:', my_softmax(y_pred1.numpy()))\n",
        "\n",
        "print('torch softmax:', torch.softmax(y_pred1, dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JudbKeLnKstI",
        "outputId": "eae950e1-0aba-4d76-d12e-4de7c7cf6024"
      },
      "id": "JudbKeLnKstI",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my softmax: [0.96466315 0.01766842 0.01766842]\n",
            "torch softmax: tensor([0.9647, 0.0177, 0.0177])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_cross_entropy(true, pred):\n",
        "  loss = - sum(true * np.log(pred))\n",
        "  return loss #/ pred.shape[0] as it seems torch crossentropy doesn use normalization\n",
        "\n",
        "print(f'my cross entropy loss 1: {my_cross_entropy(y_true.numpy(), my_softmax(y_pred1.numpy())):.4f}')\n",
        "print(f'my cross entropy loss 2: {my_cross_entropy(y_true.numpy(), my_softmax(y_pred2.numpy())):.4f}')\n",
        "\n",
        "# torch crossentropy applys softmax itself so we dont need to write it here\n",
        "# size of parameteres should be nsamples x nclasses thats why we are using .view\n",
        "# and also y_true should not be one hot encoded it need just lableb thats why we use tensor([0])\n",
        "loss = nn.CrossEntropyLoss()\n",
        "print(f'torch cross entropy loss 1: {loss(y_pred1.view(1,-1), torch.tensor([0])):.4f}')\n",
        "print(f'torch cross entropy loss 2: {loss(y_pred2.view(1,-1), torch.tensor([0])):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN9bvJ3cHyCm",
        "outputId": "9fb92b68-c26a-4362-c8af-0d0ba0bfdc26"
      },
      "id": "NN9bvJ3cHyCm",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my cross entropy loss 1: 0.0360\n",
            "my cross entropy loss 2: 14.1269\n",
            "torch cross entropy loss 1: 0.0360\n",
            "torch cross entropy loss 2: 14.1269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MNIST**"
      ],
      "metadata": {
        "id": "j1u4-A0RkfR6"
      },
      "id": "j1u4-A0RkfR6"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# initialize some hyper parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "train_df = torchvision.datasets.MNIST(root='./data', train=True, \n",
        "                                      transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "test_df = torchvision.datasets.MNIST(root='./data', train=False, \n",
        "                                     transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_df, \n",
        "                                           batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_df, \n",
        "                                          batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "F_PUAFHgkhdA"
      },
      "id": "F_PUAFHgkhdA",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "data = dataiter.next()\n",
        "samples, labels = data\n",
        "print(samples.shape, labels.shape)\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.imshow(samples[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eiGRXx39k0lz",
        "outputId": "2d36632d-ce14-46ec-aebb-84b11dbe5883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "id": "eiGRXx39k0lz",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28]) torch.Size([128])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
      ],
      "metadata": {
        "id": "r0Dge5QNmMoD"
      },
      "id": "r0Dge5QNmMoD",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.view(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "                    "
      ],
      "metadata": {
        "id": "2JxpMoZIn_zr",
        "outputId": "0fe020d0-e152-4833-a939-9d305f83a1d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2JxpMoZIn_zr",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 0.1607\n",
            "Epoch [1/10], Step [200/469], Loss: 0.1887\n",
            "Epoch [1/10], Step [300/469], Loss: 0.1718\n",
            "Epoch [1/10], Step [400/469], Loss: 0.1291\n",
            "Epoch [2/10], Step [100/469], Loss: 0.0893\n",
            "Epoch [2/10], Step [200/469], Loss: 0.0561\n",
            "Epoch [2/10], Step [300/469], Loss: 0.1799\n",
            "Epoch [2/10], Step [400/469], Loss: 0.1269\n",
            "Epoch [3/10], Step [100/469], Loss: 0.3027\n",
            "Epoch [3/10], Step [200/469], Loss: 0.0292\n",
            "Epoch [3/10], Step [300/469], Loss: 0.0328\n",
            "Epoch [3/10], Step [400/469], Loss: 0.1316\n",
            "Epoch [4/10], Step [100/469], Loss: 0.0633\n",
            "Epoch [4/10], Step [200/469], Loss: 0.0355\n",
            "Epoch [4/10], Step [300/469], Loss: 0.0233\n",
            "Epoch [4/10], Step [400/469], Loss: 0.0638\n",
            "Epoch [5/10], Step [100/469], Loss: 0.0385\n",
            "Epoch [5/10], Step [200/469], Loss: 0.0519\n",
            "Epoch [5/10], Step [300/469], Loss: 0.0544\n",
            "Epoch [5/10], Step [400/469], Loss: 0.0881\n",
            "Epoch [6/10], Step [100/469], Loss: 0.0707\n",
            "Epoch [6/10], Step [200/469], Loss: 0.1176\n",
            "Epoch [6/10], Step [300/469], Loss: 0.1155\n",
            "Epoch [6/10], Step [400/469], Loss: 0.0523\n",
            "Epoch [7/10], Step [100/469], Loss: 0.0083\n",
            "Epoch [7/10], Step [200/469], Loss: 0.0159\n",
            "Epoch [7/10], Step [300/469], Loss: 0.0106\n",
            "Epoch [7/10], Step [400/469], Loss: 0.0793\n",
            "Epoch [8/10], Step [100/469], Loss: 0.0115\n",
            "Epoch [8/10], Step [200/469], Loss: 0.0721\n",
            "Epoch [8/10], Step [300/469], Loss: 0.0698\n",
            "Epoch [8/10], Step [400/469], Loss: 0.0145\n",
            "Epoch [9/10], Step [100/469], Loss: 0.0927\n",
            "Epoch [9/10], Step [200/469], Loss: 0.0218\n",
            "Epoch [9/10], Step [300/469], Loss: 0.0463\n",
            "Epoch [9/10], Step [400/469], Loss: 0.0024\n",
            "Epoch [10/10], Step [100/469], Loss: 0.0267\n",
            "Epoch [10/10], Step [200/469], Loss: 0.0006\n",
            "Epoch [10/10], Step [300/469], Loss: 0.2074\n",
            "Epoch [10/10], Step [400/469], Loss: 0.0195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "id": "kZJELR69p50v",
        "outputId": "96710197-58a5-4cdb-c188-05d3fb1465f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kZJELR69p50v",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.27 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TpxJotDYqMym"
      },
      "id": "TpxJotDYqMym",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "raphael.kalandadze",
      "language": "python",
      "name": "raphael.kalandadze"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}