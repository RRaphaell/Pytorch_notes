{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pa3oOp8gYv8D"
      },
      "id": "pa3oOp8gYv8D",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Basic operations**"
      ],
      "metadata": {
        "id": "38AO11J2oiIm"
      },
      "id": "38AO11J2oiIm"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "gmM5lKAzYwxJ",
        "outputId": "200e1ed7-9f89-4016-cb83-2a41f14b4286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gmM5lKAzYwxJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "print(x.size())"
      ],
      "metadata": {
        "id": "WEVfmp1tY9y-",
        "outputId": "8fb06826-1990-4946-f64b-4cd933fbc918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WEVfmp1tY9y-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1260, 0.8862, 0.8999]], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1,2,3])\n",
        "x"
      ],
      "metadata": {
        "id": "lp9MhngKZYS6",
        "outputId": "58234fb1-e6ef-4db0-a7ad-c9271cefbee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lp9MhngKZYS6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inplace\n",
        "x = torch.rand(1,3)\n",
        "x.mul_(0)\n",
        "x"
      ],
      "metadata": {
        "id": "EgRZoOrUZdsD",
        "outputId": "05f75d23-c650-4d1c-ae33-28a691e378e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EgRZoOrUZdsD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, 2)\n",
        "x.view(4)"
      ],
      "metadata": {
        "id": "DhmGgJmxZzLm",
        "outputId": "88c4dc1d-cdf6-49f6-bc45-8185eb89dead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DhmGgJmxZzLm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3538, 0.9742, 0.0030, 0.6858])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# takes reference if it's on gpu\n",
        "x.numpy()"
      ],
      "metadata": {
        "id": "MbJHW9acaYw0",
        "outputId": "b917ea7b-3b56-4072-a15c-ebfde1a63330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MbJHW9acaYw0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35384423, 0.97419006],\n",
              "       [0.00295287, 0.6857872 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# takes reference if it's on gpu\n",
        "x = np.array([1,2,3])\n",
        "torch.from_numpy(x)"
      ],
      "metadata": {
        "id": "HPayYoFSbKnx",
        "outputId": "22d61325-93ac-4cc1-97f9-e259f07b8487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HPayYoFSbKnx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cpu\")\n",
        "  x = torch.ones(5, device=device)\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device)\n",
        "  z = x+y\n",
        "  z = z.to(\"cpu\")\n",
        "  print(z)"
      ],
      "metadata": {
        "id": "Grs3MjEHbTnQ",
        "outputId": "f41d482f-62fe-4ed9-e21f-805855ceb65a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Grs3MjEHbTnQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient for scalars\n",
        "x = torch.ones(3, requires_grad=True)\n",
        "y = x + 2\n",
        "z = y*y*2\n",
        "z = z.mean()\n",
        "print(y)\n",
        "print(z)\n",
        "z.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPD-pVWnHJXr",
        "outputId": "1d70e30c-a44e-405c-a1ee-01cef9638c13"
      },
      "id": "qPD-pVWnHJXr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3.], grad_fn=<AddBackward0>)\n",
            "tensor(18., grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 4., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient for scalars\n",
        "x = torch.ones(3, requires_grad=True)\n",
        "y = x + 2\n",
        "z = y*y*2\n",
        "# z = z.mean()\n",
        "print(y)\n",
        "print(z)\n",
        "z.backward(gradient=torch.tensor([1,1,1]))\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zIybqrKH2cj",
        "outputId": "3168b02a-6a4a-497f-c781-2c84311035b1"
      },
      "id": "6zIybqrKH2cj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3.], grad_fn=<AddBackward0>)\n",
            "tensor([18., 18., 18.], grad_fn=<MulBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12., 12., 12.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# desible requires grad. 3 way\n",
        "# .requires_grad_(False)\n",
        "# .detach()\n",
        "# with torch.no_grad():\n",
        "\n",
        "x1 = torch.randn(3, requires_grad=True)\n",
        "x2 = torch.randn(3, requires_grad=True)\n",
        "x3 = torch.randn(3, requires_grad=True)\n",
        "x1.requires_grad_(False)\n",
        "print(x1)\n",
        "x2.detach_()\n",
        "print(x2)\n",
        "with torch.no_grad():\n",
        "  y = x3 * 2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV6yJF83NAKq",
        "outputId": "035396e2-5b84-445c-f384-73636c3ddda9"
      },
      "id": "oV6yJF83NAKq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.6437, 1.5856, 0.6697])\n",
            "tensor([0.9452, 1.2962, 0.8772])\n",
            "tensor([ 2.8175, -1.6636, -0.8369])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# warning pytorch accumulates gradients\n",
        "# model simulation\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "\n",
        "print(\"we need to clear the gradients\")\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEJCC3QrOQs-",
        "outputId": "eef1684f-ce2e-4376-fda9-707df3954514"
      },
      "id": "wEJCC3QrOQs-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n",
            "we need to clear the gradients\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # model simulation\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "y_hat = w*x\n",
        "loss = (y_hat-y)**2\n",
        "print(loss)\n",
        "loss.backward()\n",
        "w.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xZ8TrgrPJMS",
        "outputId": "511a9f44-0371-48e0-ba5f-667d23618e68"
      },
      "id": "1xZ8TrgrPJMS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Linear Regression**"
      ],
      "metadata": {
        "id": "uDrdCka0oQaI"
      },
      "id": "uDrdCka0oQaI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "\n",
        "# 0) Prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32)).view(-1, 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "    \n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "zNkG7Uld31Uq",
        "outputId": "ada60219-98d8-4fcb-f1ff-302d62a50ac2"
      },
      "id": "zNkG7Uld31Uq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 4134.0151\n",
            "epoch: 20, loss = 2910.5952\n",
            "epoch: 30, loss = 2076.9443\n",
            "epoch: 40, loss = 1508.7603\n",
            "epoch: 50, loss = 1121.4236\n",
            "epoch: 60, loss = 857.3167\n",
            "epoch: 70, loss = 677.1964\n",
            "epoch: 80, loss = 554.3298\n",
            "epoch: 90, loss = 470.5013\n",
            "epoch: 100, loss = 413.2964\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Logistic Regression**"
      ],
      "metadata": {
        "id": "X9qVwVvRoIJy"
      },
      "id": "X9qVwVvRoIJy"
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(-1, 1)\n",
        "y_test = y_test.view(-1, 1)\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqSJbBsVnukw",
        "outputId": "abd4da8c-d400-4eb8-ef9b-3a539f02440d"
      },
      "id": "LqSJbBsVnukw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.5837\n",
            "epoch: 20, loss = 0.4820\n",
            "epoch: 30, loss = 0.4177\n",
            "epoch: 40, loss = 0.3732\n",
            "epoch: 50, loss = 0.3403\n",
            "epoch: 60, loss = 0.3148\n",
            "epoch: 70, loss = 0.2942\n",
            "epoch: 80, loss = 0.2772\n",
            "epoch: 90, loss = 0.2628\n",
            "epoch: 100, loss = 0.2504\n",
            "accuracy: 0.8947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data**"
      ],
      "metadata": {
        "id": "Mfp2-7198_CH"
      },
      "id": "Mfp2-7198_CH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Custom**"
      ],
      "metadata": {
        "id": "AfAohmnm-Y35"
      },
      "id": "AfAohmnm-Y35"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset**"
      ],
      "metadata": {
        "id": "hgE5dNJC9DT3"
      },
      "id": "hgE5dNJC9DT3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a custom Dataset:\n",
        "# inherit Dataset\n",
        "# implement __init__ , __getitem__ , and __len__\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  \n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('/content/drive/MyDrive/data/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # note that we do not convert to tensor here\n",
        "        self.x_data = xy[:, 1:]\n",
        "        self.y_data = xy[:, [0]]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# create dataset\n",
        "dataset = WineDataset()"
      ],
      "metadata": {
        "id": "9k_vnTKN90lE"
      },
      "id": "9k_vnTKN90lE",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data loader**"
      ],
      "metadata": {
        "id": "42sKlnef-PJe"
      },
      "id": "42sKlnef-PJe"
    },
    {
      "cell_type": "code",
      "source": [
        "# get first sample and unpack\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)"
      ],
      "metadata": {
        "id": "PNv9HvUw_RH6",
        "outputId": "a28ebb7c-0575-463b-acd6-8e3a7b9af22e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PNv9HvUw_RH6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data transformer**"
      ],
      "metadata": {
        "id": "RpqYRIVT9JWS"
      },
      "id": "RpqYRIVT9JWS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Transforms\n",
        "# implement __call__(self, sample)\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "    # multiply inputs with a given factor\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets"
      ],
      "metadata": {
        "id": "OZX34r-A_dHO"
      },
      "id": "OZX34r-A_dHO",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Without Transform')\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor Transform')\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor and Multiplication Transform')\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)"
      ],
      "metadata": {
        "id": "FIh1iGc-_nSW",
        "outputId": "4b62e0db-86b9-4ef0-f047-fb292dfe56ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FIh1iGc-_nSW",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Transform\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n",
            "\n",
            "With Tensor Transform\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n",
            "\n",
            "With Tensor and Multiplication Transform\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
            "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
            "        4.2600e+03]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pytorch**"
      ],
      "metadata": {
        "id": "_158A5Ac9Jdh"
      },
      "id": "_158A5Ac9Jdh"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=3,\n",
        "                          shuffle=True)\n",
        "\n",
        "\n",
        "# look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = dataiter.next()\n",
        "inputs, targets = data\n",
        "print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "id": "L9MtLtvL9Gz8",
        "outputId": "99cbdcf7-3188-4eee-c626-7fc3f125a1ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "L9MtLtvL9Gz8",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 28, 28]) torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Softmax - Cross Entropy**"
      ],
      "metadata": {
        "id": "LOulOV-oHmWe"
      },
      "id": "LOulOV-oHmWe"
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic data\n",
        "y_true = torch.tensor([1, 0, 0])\n",
        "\n",
        "y_pred1 = torch.tensor([8, 4, 4], dtype=torch.float32)\n",
        "y_pred2 = torch.tensor([-5, 7, 9], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "9sOpvDuDHqDt"
      },
      "id": "9sOpvDuDHqDt",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_softmax(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "print('my softmax:', my_softmax(y_pred1.numpy()))\n",
        "\n",
        "print('torch softmax:', torch.softmax(y_pred1, dim=0))"
      ],
      "metadata": {
        "id": "JudbKeLnKstI",
        "outputId": "eae950e1-0aba-4d76-d12e-4de7c7cf6024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JudbKeLnKstI",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my softmax: [0.96466315 0.01766842 0.01766842]\n",
            "torch softmax: tensor([0.9647, 0.0177, 0.0177])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_cross_entropy(true, pred):\n",
        "  loss = - sum(true * np.log(pred))\n",
        "  return loss #/ pred.shape[0] as it seems torch crossentropy doesn use normalization\n",
        "\n",
        "print(f'my cross entropy loss 1: {my_cross_entropy(y_true.numpy(), my_softmax(y_pred1.numpy())):.4f}')\n",
        "print(f'my cross entropy loss 2: {my_cross_entropy(y_true.numpy(), my_softmax(y_pred2.numpy())):.4f}')\n",
        "\n",
        "# torch crossentropy applys softmax itself so we dont need to write it here\n",
        "# size of parameteres should be nsamples x nclasses thats why we are using .view\n",
        "# and also y_true should not be one hot encoded it need just lableb thats why we use tensor([0])\n",
        "loss = nn.CrossEntropyLoss()\n",
        "print(f'torch cross entropy loss 1: {loss(y_pred1.view(1,-1), torch.tensor([0])):.4f}')\n",
        "print(f'torch cross entropy loss 2: {loss(y_pred2.view(1,-1), torch.tensor([0])):.4f}')"
      ],
      "metadata": {
        "id": "NN9bvJ3cHyCm",
        "outputId": "9fb92b68-c26a-4362-c8af-0d0ba0bfdc26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NN9bvJ3cHyCm",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my cross entropy loss 1: 0.0360\n",
            "my cross entropy loss 2: 14.1269\n",
            "torch cross entropy loss 1: 0.0360\n",
            "torch cross entropy loss 2: 14.1269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z2n7JLtwJREP"
      },
      "id": "z2n7JLtwJREP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "raphael.kalandadze",
      "language": "python",
      "name": "raphael.kalandadze"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}